import torch
import torch.nn as nn

"""
VAE çš„çµæ§‹åˆ†ç‚º Encoderã€Latent Space(éš±è®Šæ•¸ç©ºé–“) å’Œ Decoder ä¸‰å€‹éƒ¨åˆ†ï¼š
    Encoder: å°‡è¼¸å…¥å£“ç¸®æˆæ½›åœ¨ç©ºé–“(latent space)çš„åƒæ•¸(å‡å€¼ Î¼ å’Œæ¨™æº–å·® Ïƒ)ã€‚
    Latent Space: ä½¿ç”¨ reparameterization trick å¾å¸¸æ…‹åˆ†å¸ƒä¸­å–æ¨£ zã€‚
    Decoder: å°‡ z è§£ç¢¼å›åŸæœ¬çš„æ•¸æ“šç©ºé–“ã€‚
"""
class vae(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super(vae, self).__init__()

        # Encoder: 784 -> 400 -> (Î¼, logÏƒÂ²)
        self.fc1 = nn.Linear(input_dim, hidden_dim)  # ç¬¬ä¸€å±¤éš±è—å±¤
        #ã€€è¨ˆç®—latent spaceçš„å‡å€¼ Î¼ï¼Œä»£è¡¨ã€Œæœ€å¯èƒ½çš„æ½›åœ¨è®Šæ•¸å€¼ã€
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)  # å‡å€¼ Î¼
        # è¨ˆç®—å°æ•¸è®Šç•°æ•¸ log(ÏƒÂ²)ï¼Œç”¨ä¾†æ±ºå®š Ïƒï¼ˆæ¨™æº–å·®ï¼‰ï¼Œå³è®Šæ•¸çš„ä¸ç¢ºå®šæ€§ã€‚
        # ç‚ºä»€éº¼è¦è¼¸å‡º log(ÏƒÂ²) è€Œä¸æ˜¯ Ïƒ? -> ç›´æ¥å­¸ç¿’æ¨™æº–å·® Ïƒ å¯èƒ½æœƒå°è‡´æ•¸å€¼ä¸ç©©å®šï¼Œå–å°æ•¸å¯ä»¥è®“å­¸ç¿’éç¨‹æ›´ç©©å®š
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)  # log(ÏƒÂ²)

        # Decoder: z -> 400 -> 784
        self.fc2 = nn.Linear(latent_dim, hidden_dim)  # Latent space -> éš±è—å±¤
        self.fc3 = nn.Linear(hidden_dim, input_dim)  # éš±è—å±¤ -> è¼¸å‡ºå±¤ (é‡å»º)

        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def encode(self, x):
        h = self.relu(self.fc1(x))
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar

    """
    ç‚ºä»€éº¼è¦ reparameterize ?ç‚ºä»€éº¼ä¸èƒ½ç›´æ¥ z ~ N(Î¼, ÏƒÂ²)?
    -> å› ç‚ºç›´æ¥å¾ N(Î¼, ÏƒÂ²) å–æ¨£æ˜¯ä¸å¯å¾®åˆ†çš„ï¼Œæœƒå½±éŸ¿åå‘å‚³æ’­
    reparameterize å°‡ z è½‰æ›æˆï¼šğ‘§ = ğœ‡ + Ïƒ * ğœ–
    é€™æ¨£ Î¼ å’Œ log(ÏƒÂ²) ä»ç„¶èƒ½åƒèˆ‡æ¢¯åº¦è¨ˆç®—ï¼Œä½¿å¾— VAE å¯ä»¥ç”¨æ¢¯åº¦ä¸‹é™å­¸ç¿’
    """
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)  # è¨ˆç®—æ¨™æº–å·® Ïƒ
        eps = torch.randn_like(std)  # å–æ¨™æº–å¸¸æ…‹åˆ†å¸ƒçš„éš¨æ©Ÿæ•¸
        return mu + eps * std  # ğ‘§ = ğœ‡ + ğœ * ğœ–

    def decode(self, z):
        h = self.relu(self.fc2(z))
        return self.sigmoid(self.fc3(h))  # ä½¿ç”¨ Sigmoid é™åˆ¶è¼¸å‡ºç¯„åœåœ¨ (0,1)

    def forward(self, x):
        mu, logvar = self.encode(x)  # Flatten è¼¸å…¥
        z = self.reparameterize(mu, logvar)  # å–æ¨£ latent vector
        return self.decode(z), mu, logvar
  
    
class cnn_vae(nn.Module):
    def __init__(self, latent_dim=20):
        super(cnn_vae, self).__init__()

        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # 28x28 -> 14x14
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 14x14 -> 7x7
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # 7x7 -> 4x4
            nn.ReLU()
        )

        # Flatten 128x4x4 -> latent_dim
        self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim)
        self.fc_logvar = nn.Linear(128 * 4 * 4, latent_dim)

        # å°‡ z é‚„åŸå› 128x4Ã—4
        self.fc_decode = nn.Linear(latent_dim, 128 * 4 * 4)

        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=0),  # 4x4 -> 7x7
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # 7x7 -> 14x14
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),   # 14x14 -> 28x28
            nn.Sigmoid() 
        )

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)  
        eps = torch.randn_like(std)    
        return mu + eps * std         

    def encode(self, x):
        h = self.encoder(x)
        h = h.view(h.size(0), -1) # å› ç‚ºè¼¸å…¥åˆ°fc_mu, fc_logvarï¼šå¤§å°å¿…é ˆæ˜¯ [batch_size, 128x4x4] (MNIST)
        mu, logvar = self.fc_mu(h), self.fc_logvar(h)
        return mu, logvar

    def decode(self, z):
        h = self.fc_decode(z)  # fc_decode çš„è¼¸å‡º shape = (batch, 2048)
        h = h.view(z.size(0), 128, 4, 4) 
        h = self.decoder(h)
        return h

    def forward(self, x):
        mu, logvar = self.encode(x)        
        z = self.reparameterize(mu, logvar)
        recon_x = self.decode(z)  
        return recon_x, mu, logvar